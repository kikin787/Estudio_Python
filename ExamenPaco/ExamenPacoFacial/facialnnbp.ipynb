{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Universidad Autonoma de Aguascalientes\n",
    "# Departamento: Ciencias de la Computación\n",
    "# Materia: Machine y Deep Learning\n",
    "# Profesor: Dr. Francisco Javier Luna Rosas\n",
    "# Alumnos: \n",
    "# Enrique Vélez Durán\n",
    "# Gabriel Melchor Campos\n",
    "# Carlos Fernando Nájera Ruiz\n",
    "# Cristián Israel Donato Flores\n",
    "#### Semestre: Enero-Junio 2025\n",
    "## Reconocimiento de Emociones con NNBP\n",
    "## Este programa detecta emociones en tiempo real usando una red neuronal artificial, analiza rostros captados por la cámara y predice la emoción predominante. Incluye la graficación de la pérdida del entrenamiento, la predicción de emociones a partir de imágenes y la detección en tiempo real mostrando la emoción con su nivel de confianza."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importación Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definición de la Clase EmotionNNBP\n",
    "### Este bloque define la red neuronal y sus métodos principales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmotionNNBP:\n",
    "    def __init__(self):\n",
    "        self.emotions = ['feliz', 'enojado', 'triste', 'sorprendido', 'neutral']\n",
    "        self.data_path = 'dataset'\n",
    "        self.model_path = 'emotion_model_nnbp.npz'\n",
    "        self.input_size = 48 * 48\n",
    "        self.hidden_size = 256\n",
    "        self.output_size = len(self.emotions)\n",
    "        self.learning_rate = 0.001\n",
    "        self.epochs = 100\n",
    "        self.batch_size = 32\n",
    "\n",
    "        # Inicialización de pesos con Xavier/Glorot\n",
    "        self.W1 = np.random.randn(self.input_size, self.hidden_size) * np.sqrt(2.0 / self.input_size)\n",
    "        self.b1 = np.zeros((1, self.hidden_size))\n",
    "        self.W2 = np.random.randn(self.hidden_size, self.output_size) * np.sqrt(2.0 / self.hidden_size)\n",
    "        self.b2 = np.zeros((1, self.output_size))\n",
    "\n",
    "        self.face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-np.clip(x, -500, 500)))\n",
    "\n",
    "    def sigmoid_derivative(self, x):\n",
    "        return x * (1 - x)\n",
    "\n",
    "    def save_model(self):\n",
    "        np.savez(self.model_path, W1=self.W1, b1=self.b1, W2=self.W2, b2=self.b2)\n",
    "\n",
    "    def load_model(self):\n",
    "        try:\n",
    "            model_data = np.load(self.model_path)\n",
    "            self.W1 = model_data['W1']\n",
    "            self.b1 = model_data['b1']\n",
    "            self.W2 = model_data['W2']\n",
    "            self.b2 = model_data['b2']\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"Error al cargar el modelo: {e}\")\n",
    "            return False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creación del Dataset (Captura de Imágenes)\n",
    "### Este bloque captura imágenes con la cámara en tiempo real. Se guardarán en carpetas organizadas por cada emoción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def create_dataset_structure():\n",
    "        os.makedirs('dataset', exist_ok=True)\n",
    "        emotions = ['feliz', 'enojado', 'triste', 'sorprendido', 'neutral']\n",
    "        for emotion in emotions:\n",
    "            os.makedirs(os.path.join('dataset', emotion), exist_ok=True)\n",
    "\n",
    "    def capture_dataset():\n",
    "        create_dataset_structure()\n",
    "        cap = cv2.VideoCapture(0)\n",
    "\n",
    "        emotions = ['feliz', 'enojado', 'triste', 'sorprendido', 'neutral']\n",
    "\n",
    "        for emotion in emotions:\n",
    "            count = 0\n",
    "            input(f\"Presiona Enter para capturar imágenes de {emotion}...\")\n",
    "            print(f\"Capturando {emotion}... Presiona 'q' para salir.\")\n",
    "\n",
    "            while count < 140:\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "\n",
    "                gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "                faces = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml').detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "                for (x, y, w, h) in faces:\n",
    "                    face_roi = cv2.resize(gray[y:y+h, x:x+w], (48, 48))\n",
    "                    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S_%f\")\n",
    "                    file_path = os.path.join('dataset', emotion, f'{emotion}_{timestamp}.jpg')\n",
    "                    cv2.imwrite(file_path, face_roi)\n",
    "                    count += 1\n",
    "                    print(f\"Capturada {count}/140 imágenes de {emotion}\")\n",
    "\n",
    "            print(f\"Finalizada captura de {emotion}\")\n",
    "\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "    # Ejecutar solo cuando se desee capturar imágenes\n",
    "    # capture_dataset()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargar y Prepocesar Datos\n",
    "### Se cargán las imágenes desde las carpetas y se dividen en conjunto de entrenamiento y prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(self):\n",
    "    \"\"\"Carga y preprocesa las imágenes del dataset\"\"\"\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    # Verificar si existe el directorio del dataset\n",
    "    if not os.path.exists(self.data_path):\n",
    "        raise FileNotFoundError(f\"No se encontró el directorio del dataset: {self.data_path}\")\n",
    "\n",
    "    print(\"Cargando dataset...\")\n",
    "    for idx, emotion in enumerate(self.emotions):\n",
    "        emotion_path = os.path.join(self.data_path, emotion)\n",
    "\n",
    "        # Verificar si existe el directorio de la emoción\n",
    "        if not os.path.exists(emotion_path):\n",
    "            print(f\"Advertencia: No se encontró el directorio para {emotion}\")\n",
    "            continue\n",
    "\n",
    "        # Obtener lista de imágenes\n",
    "        image_files = [f for f in os.listdir(emotion_path) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "\n",
    "        if not image_files:\n",
    "            print(f\"Advertencia: No se encontraron imágenes para {emotion}\")\n",
    "            continue\n",
    "\n",
    "        print(f\"Cargando imágenes de {emotion}: {len(image_files)} encontradas\")\n",
    "\n",
    "        for img_file in image_files:\n",
    "            img_path = os.path.join(emotion_path, img_file)\n",
    "            try:\n",
    "                # Leer y preprocesar imagen\n",
    "                img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "                if img is None:\n",
    "                    print(f\"Error al cargar imagen: {img_path}\")\n",
    "                    continue\n",
    "\n",
    "                # Asegurar que la imagen sea 48x48\n",
    "                img = cv2.resize(img, (48, 48))\n",
    "\n",
    "                # Aplanar y normalizar la imagen\n",
    "                img_flat = img.flatten() / 255.0\n",
    "\n",
    "                X.append(img_flat)\n",
    "                y.append(idx)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error procesando {img_path}: {e}\")\n",
    "                continue\n",
    "\n",
    "    if not X or not y:\n",
    "        raise ValueError(\"No se pudieron cargar imágenes. Asegúrate de capturar el dataset primero.\")\n",
    "\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    # Convertir etiquetas a one-hot encoding\n",
    "    y = to_categorical(y, num_classes=len(self.emotions))\n",
    "\n",
    "    print(f\"\\nDataset cargado exitosamente:\")\n",
    "    print(f\"Tamaño del dataset: {len(X)} imágenes\")\n",
    "    print(f\"Dimensiones de entrada: {X.shape}\")\n",
    "    print(f\"Dimensiones de salida: {y.shape}\")\n",
    "\n",
    "    # Dividir en conjunto de entrenamiento y prueba\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    print(f\"\\nConjunto de entrenamiento: {X_train.shape[0]} imágenes\")\n",
    "    print(f\"Conjunto de prueba: {X_test.shape[0]} imágenes\")\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargado y Guardado del Modelo\n",
    "### Carga el entrenamiento y guarda el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(self):\n",
    "    \"\"\"Guarda el modelo en formato .npz\"\"\"\n",
    "    np.savez(self.model_path.replace('.npy', '.npz'),\n",
    "            W1=self.W1, b1=self.b1, W2=self.W2, b2=self.b2)\n",
    "\n",
    "def load_model(self):\n",
    "    \"\"\"Carga el modelo desde formato .npz\"\"\"\n",
    "    try:\n",
    "        model_data = np.load(self.model_path.replace('.npy', '.npz'))\n",
    "        self.W1 = model_data['W1']\n",
    "        self.b1 = model_data['b1']\n",
    "        self.W2 = model_data['W2']\n",
    "        self.b2 = model_data['b2']\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error al cargar el modelo: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento del Modelo\n",
    "### Entrena la red neuronal con las imágenes capturadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(self):\n",
    "    try:\n",
    "        X_train, X_test, y_train, y_test = self.load_data()\n",
    "    except Exception as e:\n",
    "        print(f\"Error al cargar los datos: {e}\")\n",
    "        return\n",
    "\n",
    "    print(\"Iniciando entrenamiento...\")\n",
    "    losses = []\n",
    "    best_loss = float('inf')\n",
    "    patience = 5\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(self.epochs):\n",
    "        # Mini-batch training\n",
    "        indices = np.random.permutation(len(X_train))\n",
    "        total_loss = 0\n",
    "\n",
    "        for i in range(0, len(X_train), self.batch_size):\n",
    "            batch_indices = indices[i:i + self.batch_size]\n",
    "            X_batch = X_train[batch_indices]\n",
    "            y_batch = y_train[batch_indices]\n",
    "\n",
    "            # Forward pass\n",
    "            Z1 = np.dot(X_batch, self.W1) + self.b1\n",
    "            A1 = self.sigmoid(Z1)\n",
    "            Z2 = np.dot(A1, self.W2) + self.b2\n",
    "            A2 = self.sigmoid(Z2)\n",
    "\n",
    "            # Backward pass\n",
    "            loss = np.mean((y_batch - A2) ** 2)\n",
    "            total_loss += loss\n",
    "\n",
    "            error_output = (y_batch - A2) * self.sigmoid_derivative(A2)\n",
    "            error_hidden = np.dot(error_output, self.W2.T) * self.sigmoid_derivative(A1)\n",
    "\n",
    "            # Update weights and biases\n",
    "            self.W2 += self.learning_rate * np.dot(A1.T, error_output)\n",
    "            self.b2 += self.learning_rate * np.sum(error_output, axis=0, keepdims=True)\n",
    "            self.W1 += self.learning_rate * np.dot(X_batch.T, error_hidden)\n",
    "            self.b1 += self.learning_rate * np.sum(error_hidden, axis=0, keepdims=True)\n",
    "\n",
    "        avg_loss = total_loss / (len(X_train) / self.batch_size)\n",
    "        losses.append(avg_loss)\n",
    "\n",
    "        if epoch % 5 == 0:\n",
    "            print(f'Época {epoch}/{self.epochs} - Pérdida: {avg_loss:.4f}')\n",
    "\n",
    "        # Early stopping\n",
    "        if avg_loss < best_loss:\n",
    "            best_loss = avg_loss\n",
    "            patience_counter = 0\n",
    "            # Guardar mejor modelo\n",
    "            self.save_model()\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(\"Early stopping activado\")\n",
    "                break\n",
    "\n",
    "    self.plot_training_loss(losses)\n",
    "    print(\"Entrenamiento completado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gráfica la perdida del entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_loss(self, losses):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(losses)\n",
    "    plt.xlabel('Épocas')\n",
    "    plt.ylabel('Pérdida')\n",
    "    plt.title('Evolución de la pérdida en el entrenamiento')\n",
    "    plt.grid(True)\n",
    "    plt.savefig('training_loss_nnbp.png')\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicción de emociones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_emotion(self, face_roi):\n",
    "    face_roi = face_roi.flatten() / 255.0  \n",
    "    Z1 = np.dot(face_roi, self.W1) + self.b1  \n",
    "    A1 = self.sigmoid(Z1)\n",
    "    Z2 = np.dot(A1, self.W2) + self.b2  \n",
    "    A2 = self.sigmoid(Z2)\n",
    "    return np.argmax(A2), np.max(A2)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detección de Emociones en Tiempo Real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_emotion(self):\n",
    "    if not self.load_model():\n",
    "        print(\"Por favor, entrena el modelo primero.\")\n",
    "        return\n",
    "\n",
    "    cap = cv2.VideoCapture(0)  # Inicia la cámara\n",
    "    print(\"Presiona 'q' para salir\")\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)  # Convierte a escala de grises\n",
    "        faces = self.face_cascade.detectMultiScale(gray, 1.3, 5)  # Detecta rostros\n",
    "\n",
    "        for (x, y, w, h) in faces:\n",
    "            face_roi = cv2.resize(gray[y:y+h, x:x+w], (48, 48))  # Ajusta el tamaño\n",
    "            emotion_idx, confidence = self.predict_emotion(face_roi)  # Predice emoción\n",
    "            emotion = self.emotions[emotion_idx]\n",
    "\n",
    "            # Dibujar rectángulo y etiqueta\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "            label = f\"{emotion} ({confidence:.1%})\"\n",
    "            cv2.putText(frame, label, (x, y-10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.9,\n",
    "                        (0, 255, 0), 2)\n",
    "\n",
    "        cv2.imshow('Detector de Emociones', frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):  # Salir con 'q'\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Menú Principal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    modelo = EmotionNNBP()\n",
    "    while True:\n",
    "        print(\"\\nSistema de Reconocimiento de Emociones NNBP\")\n",
    "        print(\"============================================\")\n",
    "        print(\"0. Salir\")\n",
    "        print(\"1. Capturar dataset\")\n",
    "        print(\"2. Entrenar modelo\")\n",
    "        print(\"3. Detectar emociones en tiempo real\")\n",
    "\n",
    "        try:\n",
    "            opcion = int(input(\"\\nElige una opción (0-3): \"))\n",
    "\n",
    "            if opcion == 0:\n",
    "                print(\"¡Hasta luego!\")\n",
    "                break\n",
    "            elif opcion == 1:\n",
    "                modelo.capture_dataset()\n",
    "            elif opcion == 2:\n",
    "                modelo.train()\n",
    "            elif opcion == 3:\n",
    "                if not os.path.exists(modelo.model_path.replace('.npy', '.npz')):\n",
    "                    print(\"Error: No se encontró el modelo entrenado.\")\n",
    "                    print(\"Por favor, entrena el modelo primero (opción 2).\")\n",
    "                else:\n",
    "                    modelo.detect_emotion()\n",
    "            else:\n",
    "                print(\"Opción no válida. Por favor, elige una opción entre 0 y 3.\")\n",
    "        except ValueError:\n",
    "            print(\"Por favor, ingresa un número válido.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
